{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyNoon Week 9 - Exercise\n",
    "\n",
    "## 1. AI Exercises\n",
    "\n",
    "### 1a. Classification Confidence\n",
    "\n",
    "-   AI will not always generate good results - have a look at the label\n",
    "    assigned to the `When to plant tomatoes` title in the tutorial.\n",
    "-   The classifier we used in the tutorial returns more than just the\n",
    "    best matching label, it also returns a **score** for each label to\n",
    "    give us an indication of the classifier’s confidence in its\n",
    "    classification.\n",
    "-   Modify your code from the tutorial to include the score for each\n",
    "    possible label in columns of `title_df`.\n",
    "    -   **Tip:** You might find it easier to construct `title_details`\n",
    "        using a `for` loop instead of a list comprehension.\n",
    "    -   **Tip:** Consider using Python’s `zip()` function to combine the\n",
    "        lists of labels and scores returned by the classifier.\n",
    "\n",
    "### 1b. Try out another AI model\n",
    "\n",
    "-   Try out one or more other models from\n",
    "    [huggingface.co](https://huggingface.co/models)\n",
    "-   The model page will usually include example code showing you how to\n",
    "    use\n",
    "-   Some models might require the computational power of GPU (Graphics\n",
    "    Processing Unit) to run efficiently - fortunately, Google Colab can\n",
    "    run your code on a computer that has access to a GPU.\n",
    "    -   You’ll need to select a runtime with a GPU from the option menu\n",
    "        next to your RAM and CPU usage in the top-right corner of Colab.\n",
    "-   You might like to try:\n",
    "    -   Generating text with an Instruct-trained (i.e. ChatGPT-like)\n",
    "        Large Language Model (LLM), such as:\n",
    "        -   [dolly-v2](https://huggingface.co/databricks/dolly-v2-3b)\n",
    "            -   Run `!pip install accelerate` and restart the Colab\n",
    "                session from the `Runtme` menu first.\n",
    "        -   [llama2](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)\n",
    "            -   Requires you to accept the license and authenticate with\n",
    "                HuggingFace from your code\n",
    "    -   Detecting objects in an image with\n",
    "        <https://huggingface.co/facebook/detr-resnet-50>\n",
    "    -   Answer questions from a DataFrame with\n",
    "        <https://huggingface.co/microsoft/tapex-large-finetuned-wtq>\n",
    "\n",
    "### 1c. LangChain\n",
    "\n",
    "Have a look at the\n",
    "[LangChain](https://python.langchain.com/docs/get_started/quickstart)\n",
    "package for more examples of using Python to build applications powered\n",
    "by generative AI.\n",
    "\n",
    "## 2. Futurecoder\n",
    "\n",
    "Complete the final lesson on [futurecoder.io](https://futurecoder.io)\n",
    "(this is a mini-project, so it might take a bit longer):\n",
    "\n",
    "1.  Tic Tac Toe Project\n",
    "\n",
    "> You can check which lesson you are up to on Futurecoder from the\n",
    "> `Table of Contents` link at the top of the Futurecoder webpage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
